


This section discusses the literature related to the problem of target localisation <once have nailed down problem definition/description, re-state here>. The necessary background knowledge to fully understand these approaches is provided in the next section (section \ref{sec:StochasticTargetLocalizationBackground}).


The problem of stochastic target localisation has been studied extensively and there is a large body of literature behind it. The study of problem can be traced back to a series of three papers by \citeauthor{KoopmanTheoryOfSearchTargetDetection} \cite{Koopman1956THEBASES}, \cite{KoopmanTheoryOfSearchTargetDetection}, \cite{Koopman1957TheEffort}. The first of the three, entitled "Kinematic Bases", references World War $\Romannum{2}$ as a primary motivation behind the series, citing "\textit{detection, location, and identification of targets}" as a key problem which required an urgent solution \cite{Koopman1956THEBASES}. Three key general features of search are identified, which are addressed individually in each of the three papers:
\begin{enumerate}
    \item "\textit{Kinematic Bases}" addresses search with a focus on the kinematic constraints involving the positions, geometric configurations and motion of the seachers and targets \cite{Koopman1956THEBASES}.

    \item "\textit{Target Detection}" is concerned with the stochastic nature of the sensors and instrumentation that is used when navigating and detecting \cite{KoopmanTheoryOfSearchTargetDetection}.
 
    \item "\textit{The Optimum Distribution of Searching Effort}" examines the probability of contact under the stated conditions. It also provides insight on how to optimise results by choosing a search strategy which maximises the probability of contact \cite{Koopman1957TheEffort}.
\end{enumerate}
This introduced the problem in structured manner and offered a strong insight into potential future research. In subsequent years the research branched into problems that involved the motion of both the searchers and the target \cite{Stone1980OptimalTargets}, or just the searchers \cite{Chew1966AProcedure}. Since the work in this thesis is primarily concerned with stationary targets, we refer the reader to the PhD. thesis \cite{Lau2007OptimalEnvironments} for a broad review of the literature related to search with a moving target. 

\cite{Chew1966AProcedure} explored an instance of the search problem which is very close to the version this thesis explores. The following assumptions were made
\begin{itemize}
    \item There is an object to be found in one of $R$ locations or an $R+1^{st}$ representing the absence of the object.
    \item Sampling locations for the objects returns values with a false negative rate $\alpha_i$.
    \item Boxes can be searched sequentially.
    \item All Outcomes are independent, conditional on the location of the object and the search procedure used.
    \item A loss function introduces a cost for concluding the search when the object has not been found.
\end{itemize}
A dynamic programming approach was proposed, based on \cite{Blackwell1961DiscreteProgramming}, which was shown to be optimal when restricted to a fixed number of inspections. In this case, "optimal" is taken to mean that the strategy minimises the searcher's total expected cost of searching and stopping. A stopping rule was also suggested, with a proof of desirable properties such as minimizing expected cost when using a strongly optimal search procedure.

\cite{Black1965DiscretePROBLEM} examined a discrete instance of the stochastic problem for a stationary target, following the similar assumptions as \cite{Chew1966AProcedure} above, with the exception of the object not being present (represented by the $R+1^{st}$ location) and without a cost for concluding the search when the object has not been found. A sampling policy was proposed that was shown to be optimal in terms of minimising the expected cost of the search, according to an arbitrary cost function. The optimal policy was summarised as "\textit{Always look in the region for which the posterior probability (given the failure of earlier looks) of finding the object divided by the cost is maximum.}". The policy was not described in terms of a dynamic program, which the author claims provides more transparency to the solution, as opposed to previous work.

\cite{Ross1969AStop} examined the search problem with the assumptions set out in \cite{Chew1966AProcedure} with the exception of the object not being present (represented by the $R+1^{st}$ location ). \cite{Ross1969AStop} showed that in general, an optimal search strategy exists for the problem with a penalty cost for stopping the search. He proved that when searching is warranted (i.e. the cost of stopping is small relative to the cost of further searching), the optimal search strategy is the same as in the no-penalty case, which is an intuitive result. This means that to optimally solve the general problem of searching and stopping when a penalty cost for stopping is charged (as set out in \cite{Chew1966AProcedure}), the only additional requirement to the use of the optimal search strategy is a stopping time s* that is optimal when used with that search strategy.

\cite{Chew1973OptimalProblem} iterated on his previous work \cite{Chew1966AProcedure} and outlined a best stopping rule to accompany the optimal search procedure described in \cite{Chew1966AProcedure}. This went a step further than \cite{Ross1969AStop}, since it includes the possibility that the object is not present in the search region. The optimal stopping rule was found to be derived from the optimal dynamic programming strategy outlined in \cite{Chew1966AProcedure}, subject to a realistic technical condition relating the search termination cost, the cost of searching each location and the probability of a missed detection in each location.

\cite{Kimeldorf1979BinomialObjects} studied the more general problem of locating $n$ objects hidden among $m$ boxes, where $m$ is known and $n$ is unknown. They assume that there is a cost associated with searching each box and that the distributions of $p$ (the number of boxes) and $\pi$ (the distribution objects among the boxes) are known. They also assume that they know when all the objects have been found and that there is no associated search termination cost. Their results showed that for special cases of the distributions of $n$ and $p$, optimal search strategies can be found which are an extension of the general strategy set out in \cite{Blackwell1961DiscreteProgramming}. \cite{Assaf1985OptimalApproach} tackled the same problem, but imposed the constraint that the distribution of $\pi$ is not known exactly, but some partial information is known. Their findings showed that even small random fluctuations, or statistical inaccuracies, may give rise to results that are greatly different from the results obtained when $\pi$ is perfectly known. This suggested that a robust strategy in the case of a possibly inaccurate knowledge of $\pi$ would be desirable.

Many recent approaches related to the problem of non-deteministic detection and localisation of objects follow the groundwork laid by Elfes \cite{Elfes1989UsingNavigation}, whereby an \textit{occupancy grid} is used to represent the distribution of the target over the cells of a spatial lattice. Elfes describes an occupancy grid as a "\textit{probabilistic tesselated representation of spatial information}". In simpler terms, the occupancy grid is a tesselation of a physical space over which a mobile robot is intended to operate, with each cell maintaining a probability of the presence of an object. %This is in contrast to previous approaches that typically used geometric models of the world, which enforced strong domain-specific dependencies.
The approach was taken bearing in mind recent advancements in mobile robotics, with sensing and navigation abilities that allowed the processing of information from complex environments. There is an emphasis on designing the model to deal with an environment of which little may be known in advance, which is in contrast to previous approaches which assumed most aspects of the environment were known. The occupancy grids representation was defined to maintain an estimated environment state base on spatio-temporal data. A general Bayesian update rule is stated, which takes the current cell probability of occupancy and updates it based on a new sensor reading: 
\begin{equation*}\label{eq:OccUpdateRule}
  \begin{aligned}
  \text{Probability of occupancy of grid cell } i \text{ given the set of observations } \{o_1, ..., o_{t+1}\} = \\
\frac{p(o_{t+1} | cell_i occupied) \times p(cell_i occupied | o_1, ..., o_t)}{\sum_{k=1}^{\# grid cells} p(o_{t+1} | cell_k occupied) \times p(cell_k occupied | o_1, ..., o_t)}
\end{aligned}
\end{equation*}
This allows the agent to maintain and recursively update the occupancy grid distribution based on new observations. This update rule is discussed in greater detail in section \ref{section:HMMFiltering}. Elfes lists sonar based mapping and path planning as major applications of the occupancy grid framework.

%The book "\textit{Probabilistic Robotics}" \cite{Thrun:2005:ProbabilisticRobotics} was published with the goal of "\textit{providing a comprehensive introduction to the emerging field of probabilistic robotics}", which focuses on the techniques for processing percepts and designing control strategies, through statistical techniques. Many useful techniques are explored, and in particular there are two full chapters dedicated to the problem of localisation using mobile robots. We reference it often in the subsequent background section \ref{sec:StochasticTargetLocalizationBackground}.

A decentralized Bayesian approach to coordinating multiple autonomous mobile sensors, with the goal of localising a single stationary target, is presented in \cite{Bourgault2005DecentralizedSearch}. The approach is implemented using Bayesian Filtering, discussed in greater depth in this thesis in section \ref{section:HMMFiltering}. Each autonomous airborne vehicle maintains its own probability density function (PDF) which is represented using an occupancy grid. Bayesian Distributed Data Fusion (DDF) is used to update each vehicle's individual PDF. The authors cite "\textit{scalability, modularity and adaptability}" as the motivation behind the approach. The results of running high-fidelity simulations for a target lost at sea using aerial vehicles demonstrated the feasibility of running the platform in real life.

\cite{Chung2007ASearch} proposed a general framework for the search problem, with a focus on the decision-making aspect of the agent implementing the search. An abstract sensor model was proposed, which assumed that observations are part of the set \{1,0\}, representing a positive and negative detection respectively. The sensor model assumes a false positive rate ($\alpha$) and false negative rate ($\beta$) which can be calibrated before running the search. They also utilise an occupancy grid representation, with the corresponding Bayesian update rule updating the agent's belief based on new observations. They also described the use of Wald's Sequential Probability Ratio Test (SPRT) as a termination criteria for the search \cite{Wald1945SequentialHypotheses}. The mean time to decision (TTD) was reported for simulation runs which varied the search strategy for a single stationary target in a 10 $\times$ 10 grid, against which future results could be compared. The same authors extended this approach to multiple agents in \cite{Chung2008Multi-agentFramework}, finding that the best results were achieved using a hybrid search strategy (different search strategies were used for each agents, which had a complementary effect).

\cite{Waharte2009CoordinatedUAVs}, \cite{Waharte2010ProbabilisticUAVs} and \cite{Waharte2010SupportingUAVsb} were published by authors working on the same project, named Sensing Unmanned Autonomous Aerial Vehicles (SUAAVE) \cite{Cameron2010SUAAVE:Details}. The work is expands on the framework described in \cite{Chung2007ASearch}. Methods for dealing with observations that spanned multiple cells in the occupancy grid, motivated by the case that observations in the form of camera images do not always align with the grid. They proposed the use of a feature-matching algorithm based on the SURF \cite{Bay2006SURF:Features} algorithm as a detection method based on aerial images. More search strategies were proposed and evaluated through the results of simulation, which demonstrated the effectiveness of a multi-vehicle approach.

\cite{Chung2012AnalysisStrategies} revisited the problem set out by the same authors in \cite{Chung2007ASearch}, providing 

A common feature in the problem definition in the literature is that the system of agents are assumed to work in a partially observable environment\cite{Symington2010ProbabilisticRAVs}, \cite{Chung2008Multi-agentFramework}, \cite{WongMulti-vehicleTargets}. Many recent approaches follow the groundwork laid by Elfes\cite{ElfesUsingNavigation}, whereby an "occupancy field" is used to represent the distribution of the target over the cells of a spatial lattice.