\section{Conclusion and Future Work}
%\note{From C\&B: In contrast with these previous works, the pre-sented research herein offers a sequential Bayesian formulation that addresses joint dependence of probabilities, the presence of both false-negative and false-positive detections, and constraints on searcher motion}

%\note{however,  such  costly near-optimal approaches may be less desirable than algorithms that provide “good enough” solutions, where the application re-quires computationally limited platforms, such as educational robots  or  miniaturized  embedded  system}

This chapter described a system which was designed to solve the problem of \textit{target localisation} using RAVs. Our system design was based on previous work, outlined in Section \ref{sec:StochasticTargetLocalisationRelatedLiterature}. The system's performance was analysed using Monte Carlo simulation and we explored the trade-off between minimising Time-To-Decision (TTD) against drawing incorrect conclusions. The results largely matched what we expected to see, but they offer a solid basis on which to set system parameters in order to achieve a desired level of performance. We evaluated four search strategies. Two were adaptive, $\epsilon$-greedy search and Saccadic search, meaning they sampled the search region in a biased manner in the hope of converging quickly on the target location. Two were unbiased, Sweep search and Random search, which offered a baseline for comparison and facilitated analysis which was useful in showing how the system reacts to perturbations in the values of the parameters.

\subsection{Varying Initial Distribution}
We first found that the shape of the initial belief distribution has a large bearing on the time-to-decision, where the use of an uninformed initial belief distribution causes a large increase in the search time relative to the use of an initial belief distribution that is aligned with the shape of the true distribution. The effect was greatest while using the adaptive search methods, which offered respective reductions in mean time to decision of 80.1\% and 85.3\% for the $\epsilon$-greedy search and Saccadic search strategies. The results also showed that the rate at which the system incorrectly concluded that the target was not present also dropped significantly, with respective reduction in mean time to decision of 80.1\% and 75.6.3\% for the $\epsilon$-greedy search and Saccadic search strategies. \par

\subsection{Varying Initial Cumulative Probability of Target Presence}
When the initial cumulative belief that the target was present for a uniform distribution was set to 0.25, we observed a drop in the mean time to decision for all search strategies. The adaptive strategies resampled the locations of false positives, which quickly drove the cumulative belief below the lower SPRT threshold prematurely. The non-adaptive strategies also experienced enough negative observations in relation to positives to terminate prematurely. This led to an inflated rate at which the system concluded the source was not present. In the case where the initial cumulative belief that the target was present started at 0.75, the adaptive methods saw a slight increase in the mean time to decision relative to the case where the initial cumulative belief was set to 0.5. The evidence suggested that since a comparable number of consecutive positive observations at the true target location would push the agent's belief over the SPRT upper threshold, the relatively high number of samples needed to make a negative conclusion was the cause. The non-adaptive methods saw a decrease in the mean time to decision because the initial belief started closer to the boundary and required  fewer positive observations to cross the upper SPRT threshold.\par

\subsection{Varying Sensor Model Parameters}
When we set the sensor model parameters to under-estimate the actual false positive and false negative rates of observations, the results we observed matched our expectations. Since the model was more confident about observations, the agent's belief fluctuated more aggressively, which made it easier to cross the upper and lower decision thresholds. This led to a drop in the mean time to decision for all search strategies relative the case with the correctly calibrated sensor ( a reduction in mean TTD of 40.4\%, 37.4\%, 71.4\%, 78.0\% for $\epsilon$-greedy, Saccadic, Random and Sweep respectively). Conversely, when the sensor model parameters over-estimated the FPR and FNR of the sensor, the agent's belief fluctuated in a much more gentle manner, which meant it took many more observations to reach the threshold set by the SPRT compared to the case with the correctly calibrated sensor (75.0\%, 43.9\%, 233.7\%, 255.5\% for $\epsilon$-greedy, Saccadic, Random and Sweep respectively). When the sensor model parameters were under-estimated, the proportion of simulation runs where the target was incorrectly localised shot up, since the relative true positive rate was lower than in the case where the sensor model FPR and FNR were set to 0.2 and 0.15 respectively.\par

\subsection{Varying Number of Targets}
Multiple targets caused the mean time to decision to increase sub-linearly with the number of targets present for all search strategies. This is because the agent ran a sequential procedure, which meant information gathered while localising the first target could be used to expedite the localisation of subsequent targets. The presence of two targets instead of one increased the mean time to decision by 37.9\%, 17.7\%, 37.3\%, 25.1\% for $\epsilon$-greedy, Sweep, Saccadic and Random respectively. The presence of three targets instead of one increased the mean time to decision by 55.7\%,  28.0\%, 56.4\%, 40.2\% for $\epsilon$-greedy, Sweep, Saccadic and Random respectively. These represent marked improvements over the naive case, where re-starting the search once a target had been localised with the same initial belief distribution would have double and tripled the mean time to decision for two and three targets. The results show that as more targets were introduced to the target region, the more likely the search procedure was to terminate prematurely, falsely concluding that there were fewer targets present than there actually were. Addressing this could be part of future work.\par

\subsection{Varying Number of Search Agents}
The use of multiple agents cut the mean time to decision for each of the search strategies while maintaining the rates at which an incorrect conclusion was drawn. The use of two agents cut the mean time to decision by 42.0\%, 50.0\%, 23.4\%, 50.0\% for $\epsilon$-greedy, Sweep, Saccadic and Random respectively. The use of three agents cut the mean time to decision by 58.0\%, 66.0\%, 34.2\%, 66.4\% for $\epsilon$-greedy, Sweep, Saccadic and Random respectively. We anticipate that introducing a maximum radius in which the agents can communicate with each other, with the probability of communicating successfully inversely proportional to the distance between agents, would mean adding extra agents would have less of an effect on the mean time to decision but would help to stabilise the rates at which the system mistakenly concludes the search.

\subsection{Future Work}
Future work for the problem of target localisation has been outlined in \cite{Chung2007ASearch}, \cite{Chung2008Multi-agentFramework}, \cite{Chung2012AnalysisStrategies}, \cite{Kriheli2016OptimalInspections}. We summarise the previously identified future work, along with our own suggestions, as follows:

\begin{enumerate}

    \item We did not take into account battery limitations for the RAV agents. In reality, they would need to periodically recharge while carrying out the search, as mentioned in Section \ref{sec:SceneSurveyingBatteryConstraints} of Chapter \ref{chapter:SceneSurveying}. We hypothesise that a battery model could be learned using the Expectation-Maximisation (E-M) algorithm \cite{Dempster1977MaximumAlgorithm}. This could then be integrated with the search strategy to prevent the RAVs from running out of power while searching.
    \item In this work, all simulations were ran with a target present. Future work could investigate system performance with the absence of a target, or with the presence of false targets that could be considered as an adversarial measure taken to fool the system.
    \item We assumed that agents could localise \textit{themselves} accurately, which is not always the case. Research into how agents can perform the search without a deterministic location sensor could incorporate this extra level of uncertainty.
    \item Our simulation involving multiple agents assumed that they are homogeneous. Future work could explore the use of heterogeneous agents in carrying out the target localisation task. This could involve using agents with varying sensing capabilities, operational speeds, battery lives and search strategies. Future work could also investigate how to optimise various configurations to provide a more robust and efficient system, building on \cite{Chung2008Multi-agentFramework}.
    \item The performance measure discussed in Section \ref{sssection:PerfMeas} only takes into account the time taken to localise the target. It could be modified to take into account other factors such as energy expended by the agents. This may allow for a more realistic trade-off than solely focusing on making the correct decision in the least possible amount of time.
    \item It is becoming more common for RAVs to integrate a multitude of sensors in their platforms. For example, in the ROCSAFE project \cite{Bagherzadeh2017ROCSAFE:Incidents}, advanced lightweight senors are being developed to be used with a RAV to remotely detect potentially hazardous substances. Multi-sensor fusion techniques have been shown in certain cases to be highly effective in identifying outliers and creating more robust estimators of true environment state. The review paper \cite{Khaleghi2013MultisensorState-of-the-art} discusses challenges and promising future areas related to research involving the fusion of data from multiple sensors. Exploring the improvements that a multi-sensor approach could potentially provide could be a future avenue of research.
    \item  We followed the approach of \cite{Chung2007ASearch} in developing a sensor model. The approach is very general, but is highly susceptible to providing poor results due to miscalibration, evident in Table \ref{table:MiscalibratedSensor}. Developing a more advanced sensor model that is specific to common tasks, such as object detection, may yield a more robust and efficient system. For example, \cite{Symington2010ProbabilisticUAVs} outlines a sensor model which was calibrated with varying heights of the RAV and \cite{Thrun:2005:ProbabilisticRobotics} outlines sensor models commonly used with robotic vehicles.
    \item Running the system in a realistic setting would offer insight in the practicality of the system. For example, we ran the agent software on a desktop machine, but in reality it would likely be running on an embedded system with a reduced computational ability relative to a desktop. This may show the system is infeasible due to constraints such as memory size or processor speed. Future research could involve running the system on realistic hardware to evaluate its feasibility. In the future, we intend to run the system using the high-fidelity simulation discussed in Chapter \ref{chap:HighFidelitySim}, with the agent software running on raspberry pi devices. This will give a stronger indication of how the system may potentially perform in the real world.
    \item Further theoretical analysis of the system could offer insight into how it could be improved. In \cite{Chung2012AnalysisStrategies} and \cite{Chung2009ProbabilisticAgents}, special cases are analysed in order to elicit properties, such as the rate of change of agent belief, which can be useful in devising strategies to improve the search performance.
\end{enumerate}