\section{Results}
\note{This section includes all results of running the simulation, with reports of expected time to detection being primary focus}


\note{from c\&B analysis of sequential decision making}
\note{Consider the following setting, where a single stationary tar-get is possibly located in a10×10 search region that is depicted in Fig. 5. The initial aggregate beliefB(0) is distributed among theC= 100 cells,  where  the  height  of  the  bars  in  each  cell represents the individual cell belief values, i.e., the probabilityp0cthat the target is present in a given cell, i.e.,c in {1,...,C} . SupposeB(0) = 0.75 ,  which  corresponds  to  an  initial  likeli-hood of 75\% that the target is truly present inA at the beginning of the search process. We examine the evolution of the search decision employing the different search strategies that are presented in the previous section. The search problem parameters that are used for the simulation studies, which are presented in this section, are tabu-lated in Table I. Simulations were allowed to run to completion (i.e., a decision was made), and statistics were calculated over N= 10 000 simulation replications. The values for the detec-tion errors, i.e.,alpha and beta , were chosen to reflect a representative sensor, such as a visual camera that provides aerial imagery in an outdoor and cluttered environment, which could be further calibrated empirically, e.g., by the sensor’s receiver operating characteristic (ROC) curve. Fig.  6  illustrates  the  evolution  of  the  belief  map  as  a search  agent  that  employs  the  myopic  search  strategy  thatmoves through the search region for the given search problem parameters. The searcher attempts to inspect or “clear” cells with the highest cell belief values, which, for the example bimodal belief distribution, requires visiting one peak followed by explo-ration of the other. Note that false-positive and false-negative detections  occur  throughout  the  search  process,  although  the searcher eventually arrives at the true location of the target and correctly terminates the search}


note{From C\&B Analysis of sequential decision-making using prob. search. Consider a bounded discretized search areaA , which is de-fined byC disjoint cells. This discrete representation can charac-terize numerous environment types of diverse spatial scale, such as open areas that are relevant to maritime search operations, cluttered regions, such as obstacle-filled arenas, or structured environments, such as rooms and hallways in a building. Other factors, which include the geometry and extent of the searcher’s sensor footprint, and the size of the sought object, or other op-erational considerations (e.g., existing coordinates or reference systems) can also govern the specific cellular decomposition of the search area}

\note{More general sensor models that account for additional spatial and/or temporal dependences be-cause  of  clutter  (indoor)  or  terrain  and  atmosphere  (outdoor) can  be  constructed  (e.g.,$\alpha$ s(k),kand $\beta$ s(k),k )  but  is  deferred for future study}


\note{In other words, the greater hindrance to deciding that a target is present in the search cell is the false-positive detection probabil-ity, since false alarms tend to prevent the searcher from “trust-ing” its positive observation. In contrast, if the missed detection probability is high, then the searcher cannot declare the search cell empty of the target with high confidence without expending multiple observations in the c}


The results presented in this section are generated by running monte carlo simulations, since finding a close-form solution to the expected time to decision (ETTD) is not readily available in the general case \cite{Chung2012AnalysisStrategies}. Following the approach outlined in \cite{Chung2007ASearch}, for each set of parameters in tables \ref{table:VaryingPriorDistribution}, \ref{table:VaryingInitialBelief}, \ref{table:MiscalibratedSensor}, \ref{table:MultipleTargetEGSweep}, \ref{table:MultipleTargetSaccadicRandom} and \ref{table:VaryingNumberOfAgents} we ran 5000 simulations. The parameters that we vary in the simulations are: 
\begin{enumerate}
    \item The prior belief distribution of each agent.
    \item The initial cumulative belief that the target is present in the region.
    \item The sensor model false positive rate and false negative rate.
    \item The number of targets present in the region.
    \item The number of agents participating in the search.
\end{enumerate}
The results of the simulation show the results of varying these parameters and suggest how to set them to achieve a desired result. We focus on the mostly commonly reported metrics in the literature, which are  related to the distribution of time to decision \cite{Chung2012AnalysisStrategies}, \cite{Waharte2010ProbabilisticRAVs}, \cite{Waharte2010SupportingRAVs}, \cite{Lau2007OptimalEnvironments}. We also report on the rate at which incorrect target locations are returned and the rate at which the agents incorrectly conclude that the target is not present. 

\par For each of the simulations, we arbitrarily chose to use the SPRT cutoff criteria with the upper Type \Romannum{1} error probability set to 0.1 and the upper Type \Romannum{2} error probability set to 0.15. In practice this meant the agent would terminate the search if its cumulative belief that the target was present exceeded $\approx$ 0.895 or subceeded $\approx$ 0.143. We generated simulated sensor readings using arbitrarily chosen values of the false positive rate = 0.2 and a false negative rate = 0.15. For each simulation run, we generated random starting locations for the agents and targets in a uniformly spaced 10 $\times$ 10 grid. Unless specified otherwise, we use the following default parameters: sensor model false negative rate = 0.15, sensor model false positive rate = 0.2, initial belief distribution = uniform, initial cumulative belief target is present = 0.5, number of targets present = 1, number of active agents = 1.

\input{Chapters/MultiAgentTargetDetection/Results/SingleAgentResults.tex}


\input{Chapters/MultiAgentTargetDetection/Results/MultipleAgentResults.tex}
